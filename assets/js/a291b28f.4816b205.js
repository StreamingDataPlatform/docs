(window.webpackJsonp=window.webpackJsonp||[]).push([[48],{119:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return p})),a.d(t,"metadata",(function(){return c})),a.d(t,"toc",(function(){return s})),a.d(t,"default",(function(){return m}));var n=a(3),r=a(7),o=(a(0),a(147)),i=a(152),l=a(156),p={title:"Getting Started with Spark",sidebar_label:"Getting Started"},c={unversionedId:"spark-connectors/getting-started",id:"spark-connectors/getting-started",isDocsHomePage:!1,title:"Getting Started with Spark",description:"\x3c!--",source:"@site/docs/spark-connectors/getting-started.md",slug:"/spark-connectors/getting-started",permalink:"/docs/spark-connectors/getting-started",editUrl:"https://github.com/pravega/spark-connectors/edit/docusaurus/documentation/src/docs/getting-started.md",version:"current",sidebar_label:"Getting Started",sidebar:"mainSidebar",previous:{title:"Spark Connectors for Pravega",permalink:"/docs/spark-connectors/index"},next:{title:"Samples",permalink:"/docs/spark-connectors/samples"}},s=[{value:"Prepare Development Environment",id:"prepare-development-environment",children:[{value:"Install Operating System",id:"install-operating-system",children:[]},{value:"Install Java 11",id:"install-java-11",children:[]},{value:"Run Pravega",id:"run-pravega",children:[]},{value:"Install Apache Spark",id:"install-apache-spark",children:[]},{value:"Clone Pravega Samples Repository",id:"clone-pravega-samples-repository",children:[]}]},{value:"Tutorial 1 - Writing to Pravega",id:"tutorial-1---writing-to-pravega",children:[]},{value:"Tutorial 2 - Reading from Pravega",id:"tutorial-2---reading-from-pravega",children:[]},{value:"Where To Go Next",id:"where-to-go-next",children:[]}],b={toc:s};function m(e){var t=e.components,a=Object(r.a)(e,["components"]);return Object(o.b)("wrapper",Object(n.a)({},b,a,{components:t,mdxType:"MDXLayout"}),Object(o.b)(i.a,{toc:s,mdxType:"TOCInline"}),Object(o.b)("p",null,"You can run Apache Spark applications written in Java, Scala, or Python. Using Python is the easiest to get started."),Object(o.b)("h2",{id:"prepare-development-environment"},"Prepare Development Environment"),Object(o.b)(l.a,{feature:"nautilus",mdxType:"IfHaveFeature"},Object(o.b)("div",{className:"admonition admonition-tip alert alert--success"},Object(o.b)("div",{parentName:"div",className:"admonition-heading"},Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",{parentName:"h5",className:"admonition-icon"},Object(o.b)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},Object(o.b)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"Streaming Data Platform")),Object(o.b)("div",{parentName:"div",className:"admonition-content"},Object(o.b)("p",{parentName:"div"},"SDP users can optionally skip this entire ",Object(o.b)("em",{parentName:"p"},"Prepare Development Environment")," section. However, it is often useful to develop applications locally in a sandbox environment before deploying to a production system such as SDP. For this reason, we recommend that this section is not skipped.")))),Object(o.b)("h3",{id:"install-operating-system"},"Install Operating System"),Object(o.b)("p",null,"Install Ubuntu 20.04 LTS. Other operating systems can also be used but the commands below have only been tested\non this version."),Object(o.b)("h3",{id:"install-java-11"},"Install Java 11"),Object(o.b)("pre",null,Object(o.b)("code",{parentName:"pre",className:"language-shell"},"sudo apt-get install openjdk-11-jdk\n")),Object(o.b)("p",null,"You may have multiple versions of Java installed. Ensure that Java 11 is the default with the command below."),Object(o.b)("pre",null,Object(o.b)("code",{parentName:"pre",className:"language-shell"},"sudo update-alternatives --config java\n")),Object(o.b)("h3",{id:"run-pravega"},"Run Pravega"),Object(o.b)("p",null,"This will run a development instance of Pravega locally. The transaction parameters allow transactions to remain open for up to 30 days without lease renewals."),Object(o.b)("pre",null,Object(o.b)("code",{parentName:"pre",className:"language-shell"},"cd\ngit clone https://github.com/pravega/pravega\ncd pravega\ngit checkout r0.9\n./gradlew startStandalone \\\n    -Dcontroller.transaction.lease.count.max=2592000000 \\\n    -Dcontroller.transaction.execution.timeBound.days=30\n")),Object(o.b)("h3",{id:"install-apache-spark"},"Install Apache Spark"),Object(o.b)("p",null,"This will install a development instance of Spark locally."),Object(o.b)("p",null,"Download ",Object(o.b)("a",{parentName:"p",href:"https://www.apache.org/dyn/closer.lua/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz"},"https://www.apache.org/dyn/closer.lua/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz"),"."),Object(o.b)("pre",null,Object(o.b)("code",{parentName:"pre",className:"language-shell"},'mkdir -p ~/spark\ncd ~/spark\ntar -xzvf ~/Downloads/spark-3.0.2-bin-hadoop2.7.tgz\nln -s spark-3.0.2-bin-hadoop2.7 current\nexport PATH="$HOME/spark/current/bin:$PATH"\n')),Object(o.b)("p",null,"By default, the script ",Object(o.b)("inlineCode",{parentName:"p"},"run_spark_ap.sh")," will use an in-process Spark mini-cluster\nthat is started with the Spark job (",Object(o.b)("inlineCode",{parentName:"p"},"--master local[2]"),")."),Object(o.b)("h3",{id:"clone-pravega-samples-repository"},"Clone Pravega Samples Repository"),Object(o.b)("p",null,"This will download the Pravega samples, which includes the Spark samples."),Object(o.b)("pre",null,Object(o.b)("code",{parentName:"pre",className:"language-shell"},"cd\ngit clone https://github.com/pravega/pravega-samples\ncd pravega-samples\ngit checkout spark-connector-examples\ncd spark-connector-examples\n")),Object(o.b)("h2",{id:"tutorial-1---writing-to-pravega"},"Tutorial 1 - Writing to Pravega"),Object(o.b)("p",null,"A simple Python Spark (PySpark) applications will consist of a single ",Object(o.b)("inlineCode",{parentName:"p"},".py")," file. Our first application will be ",Object(o.b)("a",{parentName:"p",href:"https://github.com/pravega/pravega-samples/blob/spark-connector-examples/spark-connector-examples/src/main/python/stream_generated_data_to_pravega.py"},"stream_generated_data_to_pravega.py")," and it will continuously write a timestamp to a Pravega stream."),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"The first part of the application imports our dependencies, extracts a few environment variables, and obtains a ",Object(o.b)("inlineCode",{parentName:"p"},"SparkSession"),"."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python",metastring:'title="stream_generated_data_to_pravega.py"',title:'"stream_generated_data_to_pravega.py"'},'from pyspark.sql import SparkSession\nimport os\n\ncontroller = os.getenv("PRAVEGA_CONTROLLER_URI", "tcp://127.0.0.1:9090")\nallowCreateScope = os.getenv("PROJECT_NAME") is None\nscope = os.getenv("PRAVEGA_SCOPE", "spark")\ncheckPointLocation = os.getenv("CHECKPOINT_DIR",\n                               "/tmp/spark-checkpoints-stream_generated_data_to_pravega")\n\nspark = (SparkSession\n        .builder\n        .getOrCreate()\n        )\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Next, we read from a ",Object(o.b)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#creating-streaming-dataframes-and-streaming-datasets"},"rate source"),", which continuously generates rows containing a timestamp."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'(spark\n    .readStream\n    .format("rate")\n    .load()\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Next, we will use a SQL expression to define a simple transformation on the rate source output. When writing to Pravega, we will need to provide a string or binary (byte sequence) column named ",Object(o.b)("inlineCode",{parentName:"p"},"event"),", and optionally a string column named ",Object(o.b)("inlineCode",{parentName:"p"},"routing_key"),"."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'    .selectExpr("cast(timestamp as string) as event", "cast(value as string) as routing_key")\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Next, we will specify that we want to write the output every 3 seconds. When writing to Pravega, you will typically want to use the append output mode."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'    .writeStream\n    .trigger(processingTime="3 seconds")\n    .outputMode("append")\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Now we specify the target for the output. This will write to the Pravega stream named ",Object(o.b)("inlineCode",{parentName:"p"},"streamprocessing1"),"."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'    .format("pravega")\n    .option("allow_create_scope", allowCreateScope)\n    .option("controller", controller)\n    .option("scope", scope)\n    .option("stream", "streamprocessing1")\n    .option("checkpointLocation", checkPointLocation)\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Finally, we start the Spark job that we defined and wait for it to complete. Since this is an unbounded job, it will continue to run until stopped by the user."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python",metastring:'title="stream_generated_data_to_pravega.py"',title:'"stream_generated_data_to_pravega.py"'},"    .start()\n    .awaitTermination()\n)\n"))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"To run this application locally and write to your local development installation of Pravega:"),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-shell"},"./run_pyspark_app.sh src/main/python/stream_generated_data_to_pravega.py\n")),Object(o.b)("p",{parentName:"li"},"This job will continue to run and write events until stopped."))),Object(o.b)(l.a,{feature:"nautilus",mdxType:"IfHaveFeature"},Object(o.b)("ol",{start:8},Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"To deploy this Python Spark application on SDP:"),Object(o.b)("ol",{parentName:"li"},Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},Object(o.b)("a",{parentName:"p",href:"../sdp/analytics/spark/deploying#upload-common-artifacts-to-your-analytics-project"},"Upload Common Artifacts to your Analytics Project"),".")),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},Object(o.b)("a",{parentName:"p",href:"../sdp/analytics/spark/deploying#deploying-python-applications-using-the-sdp-ui"},"Deploy Python Applications using the SDP UI"),".")))))),Object(o.b)("h2",{id:"tutorial-2---reading-from-pravega"},"Tutorial 2 - Reading from Pravega"),Object(o.b)("p",null,"In this tutorial, we'll use ",Object(o.b)("a",{parentName:"p",href:"https://github.com/pravega/pravega-samples/blob/spark-connector-examples/spark-connector-examples/src/main/python/stream_pravega_to_console.py"},"stream_pravega_to_console.py"),"."),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"The beginning of this script is the same as ",Object(o.b)("inlineCode",{parentName:"p"},"stream_generated_data_to_pravega.py"),". Now we are reading from a Pravega stream source."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python",metastring:'title="stream_pravega_to_console.py"',title:'"stream_pravega_to_console.py"'},'(spark\n    .readStream\n    .format("pravega")\n    .option("controller", controller)\n    .option("allow_create_scope", allowCreateScope)\n    .option("scope", scope)\n    .option("stream", "streamprocessing1")\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"The first time that this Spark application runs, we can choose where in the stream to begin reading from. We can choose ",Object(o.b)("inlineCode",{parentName:"p"},"earliest")," or ",Object(o.b)("inlineCode",{parentName:"p"},"latest"),". If the previous execution of this Spark application saved a checkpoint in the checkpoint directory, then this option is ignored and the application will resume from exactly where it left off."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'    .option("start_stream_cut", "earliest")\n    .load()\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"When reading from a Pravega stream, the following columns will be available:"),Object(o.b)("table",{parentName:"li"},Object(o.b)("thead",{parentName:"table"},Object(o.b)("tr",{parentName:"thead"},Object(o.b)("th",{parentName:"tr",align:null},"Column name"),Object(o.b)("th",{parentName:"tr",align:null},"Data Type"),Object(o.b)("th",{parentName:"tr",align:null},"Description"))),Object(o.b)("tbody",{parentName:"table"},Object(o.b)("tr",{parentName:"tbody"},Object(o.b)("td",{parentName:"tr",align:null},"event"),Object(o.b)("td",{parentName:"tr",align:null},"binary"),Object(o.b)("td",{parentName:"tr",align:null},"The serialized event. If a string was written, this will be a UTF-8 string.")),Object(o.b)("tr",{parentName:"tbody"},Object(o.b)("td",{parentName:"tr",align:null},"scope"),Object(o.b)("td",{parentName:"tr",align:null},"string"),Object(o.b)("td",{parentName:"tr",align:null},"The name of the Pravega scope.")),Object(o.b)("tr",{parentName:"tbody"},Object(o.b)("td",{parentName:"tr",align:null},"stream"),Object(o.b)("td",{parentName:"tr",align:null},"string"),Object(o.b)("td",{parentName:"tr",align:null},"The name of the Pravega scope.")),Object(o.b)("tr",{parentName:"tbody"},Object(o.b)("td",{parentName:"tr",align:null},"segment_id"),Object(o.b)("td",{parentName:"tr",align:null},"long"),Object(o.b)("td",{parentName:"tr",align:null},"The ID of the Pravega segment containing this event.")),Object(o.b)("tr",{parentName:"tbody"},Object(o.b)("td",{parentName:"tr",align:null},"offset"),Object(o.b)("td",{parentName:"tr",align:null},"long"),Object(o.b)("td",{parentName:"tr",align:null},"The byte offset in the Pravega segment that contains this event."))))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Since we wrote a string event, we need to cast it from a UTF-8 string to a Spark string."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'    .selectExpr("cast(event as string)", "scope", "stream", "segment_id", "offset")\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Next, we write the output to the console. We will see the result in the Spark driver log."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'    .writeStream\n    .trigger(processingTime="3 seconds")\n    .outputMode("append")\n    .format("console")\n    .option("truncate", "false")\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Stateful operations in Spark must periodically write checkpoints which can be used to recover from failures. The checkpoint directory identified by the environment variable ",Object(o.b)("inlineCode",{parentName:"p"},"CHECKPOINT_DIR")," should be used for this purpose. It should be highly available until the Spark application is deleted. This should be used even for Spark applications which do not use Pravega."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'    .option("checkpointLocation", checkPointLocation)\n')))),Object(o.b)(l.a,{feature:"nautilus",mdxType:"IfHaveFeature"},Object(o.b)("div",{className:"admonition admonition-tip alert alert--success"},Object(o.b)("div",{parentName:"div",className:"admonition-heading"},Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",{parentName:"h5",className:"admonition-icon"},Object(o.b)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},Object(o.b)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"Streaming Data Platform")),Object(o.b)("div",{parentName:"div",className:"admonition-content"},Object(o.b)("p",{parentName:"div"},"When deploying on SDP, the ",Object(o.b)("inlineCode",{parentName:"p"},"CHECKPOINT_DIR")," environment variable is automatically set to an appropriate location.")))),Object(o.b)("h2",{id:"where-to-go-next"},"Where To Go Next"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("a",{parentName:"li",href:"https://spark.apache.org/docs/latest/index.html"},"Apache Spark Documentation"))))}m.isMDXComponent=!0},147:function(e,t,a){"use strict";a.d(t,"a",(function(){return b})),a.d(t,"b",(function(){return u}));var n=a(0),r=a.n(n);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function p(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var c=r.a.createContext({}),s=function(e){var t=r.a.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},b=function(e){var t=s(e.components);return r.a.createElement(c.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},d=r.a.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,i=e.parentName,c=p(e,["components","mdxType","originalType","parentName"]),b=s(a),d=n,u=b["".concat(i,".").concat(d)]||b[d]||m[d]||o;return a?r.a.createElement(u,l(l({ref:t},c),{},{components:a})):r.a.createElement(u,l({ref:t},c))}));function u(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,i=new Array(o);i[0]=d;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l.mdxType="string"==typeof e?e:n,i[1]=l;for(var c=2;c<o;c++)i[c]=a[c];return r.a.createElement.apply(null,i)}return r.a.createElement.apply(null,a)}d.displayName="MDXCreateElement"},148:function(e,t,a){"use strict";function n(e){var t,a,r="";if("string"==typeof e||"number"==typeof e)r+=e;else if("object"==typeof e)if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(a=n(e[t]))&&(r&&(r+=" "),r+=a);else for(t in e)e[t]&&(r&&(r+=" "),r+=t);return r}t.a=function(){for(var e,t,a=0,r="";a<arguments.length;)(e=arguments[a++])&&(t=n(e))&&(r&&(r+=" "),r+=t);return r}},152:function(e,t,a){"use strict";var n=a(0),r=a.n(n),o=a(148),i=a(56),l=a.n(i);function p({toc:e,isChild:t}){return e.length?r.a.createElement("ul",{className:t?"":"table-of-contents"},e.map((e=>r.a.createElement("li",{key:e.id},r.a.createElement("a",{href:`#${e.id}`,dangerouslySetInnerHTML:{__html:e.value}}),r.a.createElement(p,{isChild:!0,toc:e.children}))))):null}t.a=function({toc:e}){return r.a.createElement("div",{className:Object(o.a)(l.a.tableOfContentsInline)},r.a.createElement(p,{toc:e}))}},156:function(e,t,a){"use strict";a.d(t,"a",(function(){return r})),a.d(t,"b",(function(){return o}));var n=a(16);function r(e){const{siteConfig:t}=Object(n.default)();return t.customFields.features.includes(e.feature)?e.children:null}function o(e){const{siteConfig:t}=Object(n.default)();return!t.customFields.features.includes(e.feature)?e.children:null}}}]);