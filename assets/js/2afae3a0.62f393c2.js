(window.webpackJsonp=window.webpackJsonp||[]).push([[17,23],{169:function(e,t,a){"use strict";a.d(t,"a",(function(){return m})),a.d(t,"b",(function(){return d}));var n=a(0),r=a.n(n);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function p(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?p(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):p(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function c(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=r.a.createContext({}),s=function(e){var t=r.a.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},m=function(e){var t=s(e.components);return r.a.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},b=r.a.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,p=e.parentName,l=c(e,["components","mdxType","originalType","parentName"]),m=s(a),b=n,d=m["".concat(p,".").concat(b)]||m[b]||u[b]||o;return a?r.a.createElement(d,i(i({ref:t},l),{},{components:a})):r.a.createElement(d,i({ref:t},l))}));function d(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,p=new Array(o);p[0]=b;var i={};for(var c in t)hasOwnProperty.call(t,c)&&(i[c]=t[c]);i.originalType=e,i.mdxType="string"==typeof e?e:n,p[1]=i;for(var l=2;l<o;l++)p[l]=a[l];return r.a.createElement.apply(null,p)}return r.a.createElement.apply(null,a)}b.displayName="MDXCreateElement"},56:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return p})),a.d(t,"metadata",(function(){return i})),a.d(t,"toc",(function(){return c})),a.d(t,"default",(function(){return s}));var n=a(3),r=a(7),o=(a(0),a(169)),p={},i={unversionedId:"snippets/spark-connectors/deploy-python-spark",id:"snippets/spark-connectors/deploy-python-spark",isDocsHomePage:!1,title:"deploy-python-spark",description:"Deploying the Application on SDP",source:"@site/docs/snippets/spark-connectors/deploy-python-spark.md",slug:"/snippets/spark-connectors/deploy-python-spark",permalink:"/docs/docs/snippets/spark-connectors/deploy-python-spark",editUrl:null,version:"current"},c=[{value:"Deploying the Application on SDP",id:"deploying-the-application-on-sdp",children:[]}],l={toc:c};function s(e){var t=e.components,a=Object(r.a)(e,["components"]);return Object(o.b)("wrapper",Object(n.a)({},l,a,{components:t,mdxType:"MDXLayout"}),Object(o.b)("h2",{id:"deploying-the-application-on-sdp"},"Deploying the Application on SDP"),Object(o.b)("p",null,"Follow these steps to deploy this application on SDP."),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},Object(o.b)("a",{parentName:"p",href:"/docs/sdp/analytics/spark/deploying#upload-common-artifacts-to-your-analytics-project"},"Upload Common Artifacts to your Analytics Project"),".")),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},Object(o.b)("a",{parentName:"p",href:"/docs/sdp/analytics/spark/deploying#deploying-python-applications-using-the-sdp-ui"},"Deploy Python Applications using the SDP UI"),"."))))}s.isMDXComponent=!0},90:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return i})),a.d(t,"metadata",(function(){return c})),a.d(t,"toc",(function(){return l})),a.d(t,"default",(function(){return m}));var n=a(3),r=a(7),o=(a(0),a(169)),p=a(56),i={title:"Tutorial 1 - Writing to Pravega"},c={unversionedId:"spark-connectors/tutorial-1-writing-to-pravega",id:"spark-connectors/tutorial-1-writing-to-pravega",isDocsHomePage:!1,title:"Tutorial 1 - Writing to Pravega",description:"\x3c!--",source:"@site/docs/spark-connectors/tutorial-1-writing-to-pravega.md",slug:"/spark-connectors/tutorial-1-writing-to-pravega",permalink:"/docs/docs/spark-connectors/tutorial-1-writing-to-pravega",editUrl:"https://github.com/pravega/spark-connectors/edit/docusaurus/documentation/src/docs/tutorial-1-writing-to-pravega.md",version:"current",sidebar:"mainSidebar",previous:{title:"Prepare Development Environment",permalink:"/docs/docs/spark-connectors/prepare-development-environment"},next:{title:"Tutorial 2 - Reading from Pravega",permalink:"/docs/docs/spark-connectors/tutorial-2-reading-from-pravega"}},l=[{value:"Code Walkthrough",id:"code-walkthrough",children:[]},{value:"Running the Application Locally",id:"running-the-application-locally",children:[]}],s={toc:l};function m(e){var t=e.components,a=Object(r.a)(e,["components"]);return Object(o.b)("wrapper",Object(n.a)({},s,a,{components:t,mdxType:"MDXLayout"}),Object(o.b)("p",null,"A simple Python Spark (PySpark) applications will consist of a single ",Object(o.b)("inlineCode",{parentName:"p"},".py")," file. Our first application will be ",Object(o.b)("a",{parentName:"p",href:"https://github.com/pravega/pravega-samples/blob/spark-connector-examples/spark-connector-examples/src/main/python/stream_generated_data_to_pravega.py"},"stream_generated_data_to_pravega.py")," and it will continuously write a timestamp to a Pravega stream."),Object(o.b)("h2",{id:"code-walkthrough"},"Code Walkthrough"),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"The first part of the application imports our dependencies."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python",metastring:'title="stream_generated_data_to_pravega.py"',title:'"stream_generated_data_to_pravega.py"'},"from pyspark.sql import SparkSession\nimport os\n"))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"In a production deployment, environment variables will be used to pass environment-specific parameters to this application. This application will attempt to get these environment variables, but if they do not exist, it will use defaults that will typically work in a local development environment."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'controller = os.getenv("PRAVEGA_CONTROLLER_URI", "tcp://127.0.0.1:9090")\nallowCreateScope = os.getenv("PROJECT_NAME") is None\nscope = os.getenv("PRAVEGA_SCOPE", "spark")\ncheckPointLocation = os.getenv("CHECKPOINT_DIR",\n                               "/tmp/spark-checkpoints-stream_generated_data_to_pravega")\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"We now obtain a ",Object(o.b)("inlineCode",{parentName:"p"},"SparkSession"),"."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},"spark = (SparkSession\n        .builder\n        .getOrCreate()\n        )\n"))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Next, we read from a ",Object(o.b)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#creating-streaming-dataframes-and-streaming-datasets"},"rate source"),", which continuously generates rows containing a timestamp."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'(spark\n    .readStream\n    .format("rate")\n    .load()\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Next, we will use a SQL expression to define a simple transformation on the rate source output. When writing to Pravega, we will need to provide a string or binary (byte sequence) column named ",Object(o.b)("inlineCode",{parentName:"p"},"event"),", and optionally a string column named ",Object(o.b)("inlineCode",{parentName:"p"},"routing_key"),"."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'    .selectExpr("cast(timestamp as string) as event", "cast(value as string) as routing_key")\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Next, we will specify that we want to write the output every 3 seconds. When writing to Pravega, you will typically want to use the append output mode."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'    .writeStream\n    .trigger(processingTime="3 seconds")\n    .outputMode("append")\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Now we specify the target for the output. This will write to the Pravega stream named ",Object(o.b)("inlineCode",{parentName:"p"},"streamprocessing1"),"."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},'    .format("pravega")\n    .option("allow_create_scope", allowCreateScope)\n    .option("controller", controller)\n    .option("scope", scope)\n    .option("stream", "streamprocessing1")\n    .option("checkpointLocation", checkPointLocation)\n'))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Finally, we start the Spark job that we defined and wait for it to complete. Since this is an unbounded job, it will continue to run until stopped by the user."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-python"},"    .start()\n    .awaitTermination()\n)\n")))),Object(o.b)("h2",{id:"running-the-application-locally"},"Running the Application Locally"),Object(o.b)("p",null,"Follow these steps to run this application locally and write to your local development installation of Pravega."),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Download ",Object(o.b)("a",{parentName:"p",href:"https://github.com/pravega/pravega-samples/blob/spark-connector-examples/spark-connector-examples/src/main/python/stream_generated_data_to_pravega.py"},"stream_generated_data_to_pravega.py")," and save it to a file.")),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"To run this application locally and write to your local development installation of Pravega, we'll use ",Object(o.b)("inlineCode",{parentName:"p"},"spark-submit --master 'local[2]'"),". This will start a Spark mini-cluster on your local system and use 2 CPUs."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-shell"},"spark-submit \\\n  --master 'local[2]' \\\n  --driver-memory 4g \\\n  --executor-memory 4g \\\n  --total-executor-cores 1 \\\n  --packages io.pravega:pravega-connectors-spark-3.0_2.12:0.9.0 \\\n  stream_generated_data_to_pravega.py\n")),Object(o.b)("p",{parentName:"li"},"This job will continue to run and write events until stopped."))),Object(o.b)(p.default,{mdxType:"DeployPythonSpark"}))}m.isMDXComponent=!0}}]);