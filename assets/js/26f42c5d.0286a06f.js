(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{147:function(e,t,a){"use strict";a.d(t,"a",(function(){return m})),a.d(t,"b",(function(){return g}));var n=a(0),r=a.n(n);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function c(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=r.a.createContext({}),p=function(e){var t=r.a.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},m=function(e){var t=p(e.components);return r.a.createElement(l.Provider,{value:t},e.children)},b={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},d=r.a.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,s=e.parentName,l=c(e,["components","mdxType","originalType","parentName"]),m=p(a),d=n,g=m["".concat(s,".").concat(d)]||m[d]||b[d]||i;return a?r.a.createElement(g,o(o({ref:t},l),{},{components:a})):r.a.createElement(g,o({ref:t},l))}));function g(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,s=new Array(i);s[0]=d;var o={};for(var c in t)hasOwnProperty.call(t,c)&&(o[c]=t[c]);o.originalType=e,o.mdxType="string"==typeof e?e:n,s[1]=o;for(var l=2;l<i;l++)s[l]=a[l];return r.a.createElement.apply(null,s)}return r.a.createElement.apply(null,a)}d.displayName="MDXCreateElement"},159:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/state.synchronizer-19251aa5a0a3fa4cfcc13fd91de8ccb9.png"},198:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/producer.consumer.client.new-11f02baa6168ab16110157306eff3535.png"},199:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/stream.segment-1579f009dd616e766877367684f7c5ea.png"},200:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/segment.split.merge.overtime.new-88dcad51602de0a4473b66979a7e0747.png"},201:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/rk.segment.new-d4bbd87de8f2b3938d93d4b020a5ce3f.png"},202:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/segment.readergroup-2977811de2d104670a4e3a6a9d8c5018.png"},203:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/trx.commit.new-b51cfaf09244e52245123275c5f3cedd.png"},204:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/pravega.arch.new-10a7437f9303bc398bf3fb28f5585b10.png"},205:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/putting.all.together.new-08aced7b5f2c25605621e9e120680e39.png"},206:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/anatomy.of.log-dcc0a6a0a7106819770265bfdadc4f5f.png"},85:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return s})),a.d(t,"metadata",(function(){return o})),a.d(t,"toc",(function(){return c})),a.d(t,"default",(function(){return p}));var n=a(3),r=a(7),i=(a(0),a(147)),s={title:"Pravega Concepts"},o={unversionedId:"pravega/pravega-concepts",id:"pravega/pravega-concepts",isDocsHomePage:!1,title:"Pravega Concepts",description:"\x3c!--",source:"@site/docs/pravega/pravega-concepts.md",slug:"/pravega/pravega-concepts",permalink:"/docs/pravega/pravega-concepts",editUrl:"https://github.com/claudiofahey/pravega/edit/docusaurus/documentation/src/docs/pravega-concepts.md",version:"current",sidebar:"mainSidebar",previous:{title:"Getting Started",permalink:"/docs/pravega/getting-started"},next:{title:"Terminology",permalink:"/docs/pravega/terminology"}},c=[{value:"Introduction",id:"introduction",children:[]},{value:"Streams",id:"streams",children:[]},{value:"Events",id:"events",children:[]},{value:"Writers, Readers, Reader Groups",id:"writers-readers-reader-groups",children:[]},{value:"Stream Segments",id:"stream-segments",children:[{value:"Events in a Stream Segment",id:"events-in-a-stream-segment",children:[]},{value:"Stream Segments and Connection pooling",id:"stream-segments-and-connection-pooling",children:[]},{value:"Elastic Streams: Auto Scaling",id:"elastic-streams-auto-scaling",children:[]},{value:"Events, Stream Segments and Auto Scaling",id:"events-stream-segments-and-auto-scaling",children:[]},{value:"Stream Segments and Reader Groups",id:"stream-segments-and-reader-groups",children:[]},{value:"Ordering Guarantees",id:"ordering-guarantees",children:[]}]},{value:"Reader Group Checkpoints",id:"reader-group-checkpoints",children:[]},{value:"Transactions",id:"transactions",children:[]},{value:"State Synchronizers",id:"state-synchronizers",children:[]},{value:"Architecture",id:"architecture",children:[]},{value:"Putting the Concepts Together",id:"putting-the-concepts-together",children:[]},{value:"A Note on Tiered Storage",id:"a-note-on-tiered-storage",children:[{value:"Stream Retention Policies",id:"stream-retention-policies",children:[]}]}],l={toc:c};function p(e){var t=e.components,s=Object(r.a)(e,["components"]);return Object(i.b)("wrapper",Object(n.a)({},l,s,{components:t,mdxType:"MDXLayout"}),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#introduction"},"Introduction")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#streams"},"Streams")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#events"},"Events")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#writers-readers-reader-groups"},"Writers Readers Reader Groups")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#stream-segments"},"Stream Segments"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#events-in-a-stream-segment"},"Events in a Stream Segment")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#stream-segments-and-connection-pooling"},"Stream Segments and Connection Pooling")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#elastic-streams-auto-scaling"},"Elastic Streams Auto Scaling")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#events-stream-segments-and-auto-scaling"},"Events Stream Segments and Auto scaling")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#stream-segments-and-reader-groups"},"Stream Segments and Reader Groups")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#ordering-guarantees"},"Ordering Guarantees")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#reader-group-checkpoints"},"Reader Group Checkpoints")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#transactions"},"Transactions")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#state-synchronizers"},"State Synchronizers")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#architecture"},"Architecture")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#putting-the-concepts-together"},"Putting the Concepts Together")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#a-note-on-tiered-storage"},"A Note on Tiered Storage"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#stream-retention-policies"},"Stream Retention Policies"))))),Object(i.b)("h2",{id:"introduction"},"Introduction"),Object(i.b)("p",null,"Pravega is an open source storage system implementing ",Object(i.b)("strong",{parentName:"p"},"Streams")," as first-class primitive for storing/serving continuous and unbounded data."),Object(i.b)("p",null,"Next, we overview the key concepts in Pravega. For a concise definition of key terms of Pravega concepts, please\xa0see\xa0",Object(i.b)("a",{parentName:"p",href:"/docs/pravega/terminology"},"Terminology"),"."),Object(i.b)("h2",{id:"streams"},"Streams"),Object(i.b)("p",null,'Pravega organizes data into Streams.\xa0A Stream is a durable, elastic, append-only, unbounded sequence of bytes having good performance and strong consistency. \xa0A Pravega Stream is\nsimilar to but more flexible than a "topic" in popular message oriented middleware such as ',Object(i.b)("a",{parentName:"p",href:"https://www.rabbitmq.com/"},"RabbitMQ")," or ",Object(i.b)("a",{parentName:"p",href:"https://kafka.apache.org/"},"Apache Kafka"),"."),Object(i.b)("p",null,"Pravega Streams are based on an append-only log data structure. By using append-only logs, Pravega rapidly ingests data into durable storage. It supports a large variety of application use cases:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Stream processing with frameworks like ",Object(i.b)("a",{parentName:"li",href:"https://flink.apache.org"},"Flink"),"."),Object(i.b)("li",{parentName:"ul"},"Publish/subscribe messaging."),Object(i.b)("li",{parentName:"ul"},"NoSQL databases like Time Series Database (TSDB)."),Object(i.b)("li",{parentName:"ul"},"Workflow engines."),Object(i.b)("li",{parentName:"ul"},"Event-oriented applications, etc.\xa0")),Object(i.b)("p",null,'When a developer creates a Stream in Pravega, s/he gives the Stream a meaningful name such as "IoTSensorData" or "WebApplicationLog20170330" to inform about the type of data it stores. Moreover, Pravega Stream names are organized within Scopes. A Scope acts as a namespace for Stream names; all Stream names are unique within their Scope. Therefore, a Stream is uniquely identified by the combination of its name and Scope. Developers can also define meaningful Scope names, such as "FactoryMachines" or "HRWebsitelogs", to effectively organize collections of Streams. For example, Scopes can be used to classify Streams by tenant (in a multi tenant environment), by department in an organization or by geographic location.'),Object(i.b)("p",null,"A Stream is unbounded in size \u2013 Pravega itself does not impose any limits on how many ",Object(i.b)("a",{parentName:"p",href:"#events"},Object(i.b)("strong",{parentName:"a"},"Events"))," (i.e., bytes) are stored in a Stream. Pravega\u2019s design horizontally scales from few machines to a whole datacenter\u2019s capacity."),Object(i.b)("p",null,"Pravega Streams are divided into ",Object(i.b)("strong",{parentName:"p"},"Stream Segments")," to handle a large volume of data within a Stream. A Stream Segment is a shard, or partition of the data within a Stream. For more information, please see ",Object(i.b)("a",{parentName:"p",href:"#stream-segments"},"Stream Segments")," section."),Object(i.b)("p",null,"Applications, such as a Java program reading from an IoT sensor, write data to the tail (front) of the Stream. Analytics applications, such as a ",Object(i.b)("a",{parentName:"p",href:"https://flink.apache.org"},"Flink")," or ",Object(i.b)("a",{parentName:"p",href:"https://hadoop.apache.org/"},"Hadoop")," jobs, can read from any point in the Stream. Many applications can read and write the same Stream in parallel.\xa0Elasticity, scalability, support for large volume of Stream data and applications are the highlights of Pravega's design. More information on read and write operations in the Streams will be discussed in the ",Object(i.b)("a",{parentName:"p",href:"#writers-readers-reader-groups"},"Readers and Writers")," section."),Object(i.b)("h2",{id:"events"},"Events"),Object(i.b)("p",null,"Pravega's client API allows applications to write and read data to/from Pravega in the form of ",Object(i.b)("strong",{parentName:"p"},"Events"),". An Event is represented as a set of bytes within a Stream.\xa0For example, an Event could be as simple as a small number of bytes containing a temperature reading from an IoT sensor composed of\na timestamp, a metric identifier and a value. An Event could also be a web log data\nassociated with a user click on a website.\xa0Applications make sense of Events using\nstandard Java ",Object(i.b)("strong",{parentName:"p"},"serializers")," and ",Object(i.b)("strong",{parentName:"p"},"deserializers"),", allowing them to read and write\nobjects in Pravega similarly to reading and writing objects from\nfiles."),Object(i.b)("p",null,"Every Event has a ",Object(i.b)("strong",{parentName:"p"},"Routing Key"),'. A Routing Key is\xa0a string used by developers to group similar Events.\xa0A Routing Key is often derived from data naturally occurring in the Event,\nlike "customer-id" or "machine-id" or a declared/user-defined string. For example, a Routing Key could be a\xa0date (to group Events together by time) or it could be a IoT sensor id (to group Events by\nmachine). A Routing Key is important in defining the read and write semantics that Pravega guarantees.'),Object(i.b)("h2",{id:"writers-readers-reader-groups"},"Writers, Readers, Reader Groups"),Object(i.b)("p",null,Object(i.b)("img",{alt:"Reader Client",src:a(198).default})),Object(i.b)("p",null,"Pravega provides a client library, written in Java, that implements a convenient\nAPI for Writer and Reader applications.\xa0 The Pravega Java Client Library\nencapsulates the Wire Protocol used to communicate Pravega clients and\nservers."),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Writer:")," An application that creates Events and writes them into a Stream.\nAll data is written by appending to the tail (front) of a Stream.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Reader:")," An application that reads Events from a Stream. \xa0Readers can read\nfrom any point in the Stream.\xa0 Many Readers will be reading Events from the tail\nof the Stream.\xa0Tail reads corresponding to recently written Events are immediately delivered to Readers.\nSome Readers will read from earlier parts of the Stream (called ",Object(i.b)("strong",{parentName:"p"},"catch-up reads"),"). The application developer has control over the Reader's start position in the Stream.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Position:")," Abstraction that represents where in a Stream a Reader is currently located. The Position object can be used as a recovery\nmechanism\xa0by replacing the failed Reader by a new Reader starting at the last saved successful read Position.\xa0Using this pattern of persisting position objects, applications can be built guaranteeing exactly-once Event processing in the presence of Reader failures.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Reader Groups:"),' Readers are organized into Reader Groups.\xa0A Reader Group is a named collection of\nReaders, which together perform parallel reads from a given Stream.\xa0When a\nReader is created through the Pravega data plane API, the developer includes the\nname of the Reader Group associated with it.\xa0Pravega guarantees that each Event published\nto a Stream is sent to exactly one Reader within the Reader Group. There could\nbe one or more Readers in the Reader Group and there could be many different Reader Groups simultaneously reading from any given Stream. A Reader Group can be considered as a "composite Reader" or "distributed Reader", that allows a distributed application to read and process Stream data\nin parallel. A large amount of Stream data can be consumed by a coordinated group of Readers in a Reader Group. \xa0For example, a collection of Flink tasks processing Stream data in parallel using Reader Group.'))),Object(i.b)("p",null,"For more details on the basics of working with Pravega Readers and Writers, please see ",Object(i.b)("a",{parentName:"p",href:"/docs/pravega/basic-reader-and-writer#working-with-pravega-basic-reader-and-writer"},"Working with Pravega: Basic Reader and\nWriter"),"."),Object(i.b)("h2",{id:"stream-segments"},"Stream Segments"),Object(i.b)("p",null,"A Stream is split into a set of shards or partitions generally referred as ",Object(i.b)("strong",{parentName:"p"},"Stream Segments"),"."),Object(i.b)("p",null,Object(i.b)("img",{alt:"Stream Segment",src:a(199).default}),"\xa0"),Object(i.b)("h3",{id:"events-in-a-stream-segment"},"Events in a Stream Segment"),Object(i.b)("p",null,'The Stream Segments acts as a container for Events within the Stream. When an\nEvent is written into a Stream, it is stored in one of the Stream Segments based\non the Event\'s Routing Key. Pravega uses consistent hashing to assign Events to\nStream Segments.\xa0Event Routing Keys are hashed to form a "key space". The key\nspace is then divided into a number of partitions, corresponding to the number\nof Stream Segments. Consistent hashing determines of Events to Stream Segments.'),Object(i.b)("h3",{id:"stream-segments-and-connection-pooling"},"Stream Segments and Connection pooling"),Object(i.b)("p",null,"Event is written to one of the Stream Segments by the Pravega Client based on the Event Routing Key in the Stream. The Stream Segments are managed by the different ",Object(i.b)("a",{parentName:"p",href:"/docs/pravega/segment-store-service"},"Segment Store")," Service instances in the Stream. A new connection to a Segment Store is created even when multiple Segments are owned by the same Segment Store. Every Segment being read by the Pravega client maps to a new connection.\nThe number of connections created increases if the user is writing and reading from multiple Streams.\nThe goal of ",Object(i.b)("strong",{parentName:"p"},"connection pooling")," is to ensure a common pool of connections between the client process and the Segment Stores, which does not require a linear growth of the number of connections with the number of Segments."),Object(i.b)("h3",{id:"elastic-streams-auto-scaling"},"Elastic Streams: Auto Scaling"),Object(i.b)("p",null,"A unique feature of Pravega is that the number of parallel Stream Segments in a Stream can automatically ",Object(i.b)("strong",{parentName:"p"},"grow")," and ",Object(i.b)("strong",{parentName:"p"},"shrink")," over time based on the I/O load it receives. This feature is known as ",Object(i.b)("strong",{parentName:"p"},"Auto Scaling"),"."),Object(i.b)("p",null,"Consider the following figure that shows the relationship between Routing Keys\nand time."),Object(i.b)("p",null,Object(i.b)("img",{alt:"Stream Segment",src:a(200).default}),"\xa0"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"A Stream starts at time ",Object(i.b)("strong",{parentName:"p"},"t0")," with a configurable number of Stream Segments.\xa0 If the\nrate of data written to the Stream is constant, there will be no change in the number of Stream Segments.\xa0")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"At time ",Object(i.b)("strong",{parentName:"p"},"t1"),", the system noted an increase in the ingestion rate and splits Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 1")," into two parts. This process is referred as ",Object(i.b)("strong",{parentName:"p"},"Scale-Up")," Event.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Before ",Object(i.b)("strong",{parentName:"p"},"t1"),", Events with a Routing Key that hashes to the upper part of the key\nspace (i.e., values ranging from ",Object(i.b)("strong",{parentName:"p"},"200-399"),") would be placed in Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 1")," and those that hash into the\nlower part of the key space (i.e., values ranging from ",Object(i.b)("strong",{parentName:"p"},"0-199"),") would be placed in Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 0"),".")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"After ",Object(i.b)("strong",{parentName:"p"},"t1"),", Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 1")," is split into Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 2")," and Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 3"),". The Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 1")," is sealed and stops accepting writes. \xa0At this point in time, Events with Routing Key ",Object(i.b)("strong",{parentName:"p"},"300"),"\xa0and\xa0",Object(i.b)("em",{parentName:"p"},"above")," are written to Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 3")," and those between ",Object(i.b)("strong",{parentName:"p"},"200")," and ",Object(i.b)("strong",{parentName:"p"},"299")," would be written into Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 2"),".")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 0")," continues accepting\xa0the\xa0same range of Events as before ",Object(i.b)("strong",{parentName:"p"},"t1"),". \xa0")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Another scale-up Event occurs at time ",Object(i.b)("strong",{parentName:"p"},"t2"),", as Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 0"),"\u2019s range of Routing\nKey is split into Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 5")," and Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 4"),". Also at this time, Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 0")," is sealed\nand allows no further writes.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Stream Segments covering a contiguous range of the key space can also be merged.\xa0At\ntime ",Object(i.b)("strong",{parentName:"p"},"t3"),", Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 2"),"\u2019s range and Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 5"),"\u2019s range are merged to Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 6")," to\naccommodate a decrease in the load on the Stream."))),Object(i.b)("p",null,"When a Stream is created, it is configured with a ",Object(i.b)("strong",{parentName:"p"},"Scaling Policy")," that\ndetermines how a Stream handles the varying changes in its load. Pravega has three kinds of Scaling Policy:"),Object(i.b)("ol",null,Object(i.b)("li",{parentName:"ol"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Fixed"),": \xa0The number of Stream Segments does not vary with load.")),Object(i.b)("li",{parentName:"ol"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Data-based"),": Pravega splits a Stream Segment into multiple ones (i.e., Scale-up Event) if the number of bytes per second written to that Stream Segment increases beyond a defined threshold. Similarly, Pravega merges two adjacent Stream Segments (i.e., Scale-down Event) if the number of bytes written to them fall below a defined threshold. Note that, even if the load for a Stream Segment reaches the defined threshold, Pravega does not immediately trigger a Scale-up/down Event. Instead, the load should be satisfying the scaling policy threshold for a ",Object(i.b)("a",{parentName:"p",href:"https://github.com/pravega/pravega/blob/master/client/src/main/java/io/pravega/client/stream/ScalingPolicy.java"},"sufficient amount of time"),".")),Object(i.b)("li",{parentName:"ol"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Event-based"),":\xa0Similar to the data-based scaling policy, but it uses number of Events instead of bytes."))),Object(i.b)("h3",{id:"events-stream-segments-and-auto-scaling"},"Events, Stream Segments and Auto Scaling"),Object(i.b)("p",null,"As mentioned earlier in this section, that an Event is written into one of the Stream Segments. By considering Auto Scaling, Stream Segments performs bucketing of Events based on Routing Key and time.\xa0It is obvious that, at any given time, Events published to a Stream with a given value of Routing Key will appear in the same Stream Segment."),Object(i.b)("p",null,Object(i.b)("img",{alt:"Stream Segment",src:a(201).default}),"\xa0"),Object(i.b)("p",null,"It is also worth emphasizing that Events are written only on the active Stream\nSegments.\xa0Stream Segments that are sealed do not accept writes.\xa0In the figure above,\nat time ",Object(i.b)("strong",{parentName:"p"},"now"),", only Stream ",Object(i.b)("strong",{parentName:"p"},"Segments 3"),", ",Object(i.b)("strong",{parentName:"p"},"6")," and ",Object(i.b)("strong",{parentName:"p"},"4")," are active and the entire key space is covered between those three Stream Segments. \xa0"),Object(i.b)("h3",{id:"stream-segments-and-reader-groups"},"Stream Segments and Reader Groups"),Object(i.b)("p",null,"Stream Segments play a major role in understanding the way Reader Groups work."),Object(i.b)("p",null,Object(i.b)("img",{alt:"Stream Segment",src:a(202).default}),"\xa0"),Object(i.b)("p",null,"Pravega assigns ",Object(i.b)("em",{parentName:"p"},"zero")," ",Object(i.b)("em",{parentName:"p"},"or")," ",Object(i.b)("em",{parentName:"p"},"more")," Stream Segments to each Reader in a Reader Group. Pravega tries to balances the number of Stream Segments assigned to each Reader. In the figure above, ",Object(i.b)("strong",{parentName:"p"},"Reader B1")," reads from two Stream Segments (",Object(i.b)("strong",{parentName:"p"},"Segment 0")," and ",Object(i.b)("strong",{parentName:"p"},"Segment 3"),"), while the other Reader Group (",Object(i.b)("strong",{parentName:"p"},"Reader B2"),", ",Object(i.b)("strong",{parentName:"p"},"Reader B3"),") have only only one Stream Segment to read from.\xa0Pravega makes sure that each Stream Segment is read exactly by one Reader in any Reader Group configured with that Stream. Irrespective of  Readers being added to the Reader Group or removed from the Reader Group due to crash, Pravega reassigns Stream Segments to maintain balance among the Readers."),Object(i.b)("p",null,"The number of Stream Segments in a Stream determines the upper bound of\nparallelism of readers within a Reader Group. If there are more Stream Segments, different Reader Groups and many parallel sets of Readers can effectively consume the Stream.\xa0In the above figure, ",Object(i.b)("strong",{parentName:"p"},"Stream 1")," has four Stream Segments. The largest effective Reader Group would contain four Readers. ",Object(i.b)("strong",{parentName:"p"},"Reader Group B")," in the above figure is not quite optimal. If one more Reader was added to the Reader Group, each Reader would have one Stream Segment to process, thus maximizing read\nparallelism. However, the number of Readers in the Reader Group increases beyond\n4, at least one of the Readers will not be assigned a Stream Segment."),Object(i.b)("p",null,"If ",Object(i.b)("strong",{parentName:"p"},"Stream 1")," in the figure above experienced a ",Object(i.b)("strong",{parentName:"p"},"Scale-Down")," event, by reducing the\nnumber of Stream Segments to three, then the ",Object(i.b)("strong",{parentName:"p"},"Reader Group B"),"  will have an\nideal number of Readers."),Object(i.b)("p",null,"The number of Stream Segments change over time by using the Pravega's Auto Scaling feature as we discussed in the ",Object(i.b)("a",{parentName:"p",href:"#elastic-streams-auto-scaling"},"Auto Scaling")," section. The size of any Stream is determined by the storage capacity of the Pravega cluster. More Streams can be obtained by increasing the storage of the Pravega cluster."),Object(i.b)("p",null,"Applications can react to changes in the number of Stream Segments in a Stream by adjusting the number of Readers within a Reader Group to maintain optimal read parallelism.\xa0As a cool use case, Pravega may allow Flink to increase or decrease the number of task instances that are processing a Stream in parallel."),Object(i.b)("h3",{id:"ordering-guarantees"},"Ordering Guarantees"),Object(i.b)("p",null,"A Stream comprises a set of Segments that can change over time. Segments that overlap in their area of key space have a defined order."),Object(i.b)("p",null,"An Event written to a Stream is written to a single Stream Segment, and is ordered with respect to the Events of that Stream Segment. The existence and position of an Event within a Stream Segment is strongly consistent."),Object(i.b)("p",null,"Readers can be assigned multiple parallel Stream Segments (from different parts of key space). A Reader reading from multiple Stream Segments will interleave the Events of the Stream Segments, but the order of Events per Stream Segment is retained. Specifically, if ",Object(i.b)("strong",{parentName:"p"},"s")," is a Stream Segment, and ",Object(i.b)("strong",{parentName:"p"},"s")," contains two Events ",Object(i.b)("em",{parentName:"p"},"i.e.,")," ",Object(i.b)("strong",{parentName:"p"},"s")," ",Object(i.b)("strong",{parentName:"p"},"=")," {",Object(i.b)("strong",{parentName:"p"},"e~1"),",",Object(i.b)("strong",{parentName:"p"},"e~2"),"} where ",Object(i.b)("strong",{parentName:"p"},"e~1")," precedes ",Object(i.b)("strong",{parentName:"p"},"e~2"),". Thus, for a Reader reading Stream Segments, it is guaranteed that ",Object(i.b)("strong",{parentName:"p"},"e~1")," will be read before ",Object(i.b)("strong",{parentName:"p"},"e~2"),"."),Object(i.b)("p",null,"This results in the following ordering guarantees:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Events with the same Routing Key are consumed in the order they were written.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Events with different Routing Keys are sent to a specific Stream Segment and will always be\nread in the same order even if the Reader performs back ups and re-reads.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"If an Event has been acknowledged to its Writer or has been read by a Reader, it is guaranteed that  it will continue to exist in the same location or position for all subsequent reads until it is deleted.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"If there are multiple Readers reading a Stream and they all back up to any given point, they will never see any reordering with respect to that point. (It will never be the case that an event that they read before the chosen point now comes after or vice versa)."))),Object(i.b)("h2",{id:"reader-group-checkpoints"},"Reader Group Checkpoints"),Object(i.b)("p",null,"Pravega provides the ability for an application to initiate a ",Object(i.b)("strong",{parentName:"p"},"Checkpoint"),' on a\nReader Group. \xa0The idea with a Checkpoint is to create a consistent "point in\ntime" persistence of the state of each Reader in the Reader Group, by using a\nspecialized Event (',Object(i.b)("em",{parentName:"p"},"Checkpoint Event"),") to signal each Reader to preserve its\nstate. Once a Checkpoint has been completed, the application can use the\nCheckpoint to reset all the Readers in the Reader Group to the known consistent\nstate represented by the Checkpoint."),Object(i.b)("p",null,"For more details on working with Reader Groups, Please see\xa0",Object(i.b)("a",{parentName:"p",href:"/docs/pravega/basic-reader-and-writer#readergroup-basics"},"Reader Group Basics"),"."),Object(i.b)("h2",{id:"transactions"},"Transactions"),Object(i.b)("p",null,'Pravega supports Transactions. The idea of a Transaction is that a Writer can\n"batch" up a bunch of Events and commit them as a unit into a Stream. This is\nuseful, for example, in Flink jobs, using Pravega as a sink.\xa0The Flink job\ncan continuously produce results for some data processing and use the Transaction\nto durably accumulate the results of the processing.\xa0For example, at the end of some sort of\ntime window, the Flink job can commit the Transaction and therefore\nmake the results of the processing available for downstream processing, or in\nthe case of an error, the Transaction is aborted and the results disappear.'),Object(i.b)("p",null,"A key difference between Pravega's Transactions and similar approaches (Kafka's producer-side batching) vary with the feature durability. Events added to a Transaction are durable when the Event is acknowledged back to the Writer.\xa0However, the Events in the Transaction are ",Object(i.b)("em",{parentName:"p"},"not")," visible to Readers until the Transaction is committed by the Writer.\xa0A Transaction is a similar to a Stream and is  associated with multiple Stream Segments. \xa0When an Event is published into a\nTransaction, the Event itself is appended to a Stream Segment of the\nTransaction.\xa0"),Object(i.b)("p",null,"For example, a Stream has five Stream Segments, when a Transaction is created on that\nStream, conceptually that Transaction also has five Stream Segments.\xa0When an Event is\npublished into the Transaction, it is routed and assigned to the same numbered Stream Segment similar to Stream (i.e., Event assigned to Stream ",Object(i.b)("strong",{parentName:"p"},"Segment 3")," in the Stream will be assigned to ",Object(i.b)("strong",{parentName:"p"},"Segment 3")," in the Transaction).\xa0Once the Transaction is committed, all the Transaction Segments are automatically appended to their corresponding Stream Segment in the Stream. If the Transaction is aborted, the Transaction, all its Stream Segments and all the Events published into the Transaction are removed from Pravega."),Object(i.b)("p",null,Object(i.b)("img",{alt:"Transaction",src:a(203).default}),"\xa0"),Object(i.b)("p",null,"Events published into a Transaction are visible to the Reader only after the Transaction is committed."),Object(i.b)("p",null,"For more details on working with Transactions, please see\xa0",Object(i.b)("a",{parentName:"p",href:"/docs/pravega/transactions"},"Working with Pravega:\nTransactions"),"."),Object(i.b)("h2",{id:"state-synchronizers"},"State Synchronizers"),Object(i.b)("p",null,"Pravega implements various building blocks to materialize the Stream primitive. One of such building blocks, namely ",Object(i.b)("strong",{parentName:"p"},"State Synchronizer"),", is aimed at coordinating processes in a distributed computing environment. Internally, the ",Object(i.b)("strong",{parentName:"p"},"State Synchronizer")," uses a Pravega Stream to provide a synchronization\nmechanism for state shared between multiple processes running in a cluster and making it easier to build distributed applications. With State Synchronizer, an application developer can use Pravega to read and make changes to shared state consistently and perform optimistic locking.\xa0"),Object(i.b)("p",null,Object(i.b)("img",{alt:"State synchroner",src:a(159).default}),"\xa0"),Object(i.b)("p",null,"State Synchronizer could be used to maintain a single, shared copy of an\napplication's configuration property across all instances of that\xa0application\xa0in\na cloud. \xa0State Synchronizer could also be used to store one piece of data or a\nmap with thousands of different key value pairs. In Pravega, managing the state of Reader Groups and distribution of Readers throughout the network is implemented using State Synchronizer."),Object(i.b)("p",null,"An application developer creates a State Synchronizer on a Stream similar to the creation of a Writer. The State Synchronizer keeps a local copy of the shared state and allows faster access to the data for the application. State Synchronizer keeps track\xa0of all the changes happening in the shared state and it is responsible for performing any modification to the shared state in the Stream.\xa0Each\xa0application\xa0instance uses the State Synchronizer, to remain updated with the\nchanges by pulling updates to the shared state and modifying the local copy of the\ndata. Consistency is maintained through a conditional append style of updates\nto the shared state through the State Synchronizer, making sure that updates are\nmade only to the most recent version of the shared state."),Object(i.b)("p",null,'The State Synchronizer can occasionally be "compacted" by compressing and removing older updates, while retaining only the most recent version of the state in the backing Stream. This feature assures the application developers, that the shared state does not grow unchecked.'),Object(i.b)("p",null,"State Synchronizer works effectively when most updates to shared state are small in\ncomparison to the total data size being stored. This can be achieved by allowing them to be written as\nsmall deltas. As with any optimistic concurrency system, State Synchronizer is\nnot at its best when many processes attempt for simultaneous updates on the same piece of data."),Object(i.b)("p",null,"For more details on working with State Synchronizers, please see\xa0",Object(i.b)("a",{parentName:"p",href:"/docs/pravega/state-synchronizer"},"Working with Pravega:\nState Synchronizer"),"."),Object(i.b)("h2",{id:"architecture"},"Architecture"),Object(i.b)("p",null,"The following figure depicts the components deployed by Pravega:"),Object(i.b)("p",null,Object(i.b)("img",{alt:"pravega high level architecture",src:a(204).default})),Object(i.b)("p",null,"Pravega is deployed as a distributed system \u2013 a cluster of servers and storage\ncoordinated to run Pravega called a ",Object(i.b)("strong",{parentName:"p"},"Pravega cluster"),". \xa0"),Object(i.b)("p",null,"Pravega presents a software-defined storage (SDS) architecture formed by ",Object(i.b)("strong",{parentName:"p"},"Controller")," instances\n(",Object(i.b)("em",{parentName:"p"},"control plane"),") and Pravega Servers (",Object(i.b)("em",{parentName:"p"},"data plane"),"). The set of Pravega Servers is collectively known as the ",Object(i.b)("strong",{parentName:"p"},"Segment Store"),".\xa0"),Object(i.b)("p",null,"The set of Controller instances together forms the control plane of Pravega, providing\nfunctionality to ",Object(i.b)("em",{parentName:"p"},"create, update")," and ",Object(i.b)("em",{parentName:"p"},"delete")," Streams. Further, it extends the functionality to retrieve\xa0information about the Streams,\xa0monitor the health of the Pravega cluster, gather metrics, etc.  There\nare usually multiple (recommended at least 3) Controller instances running in a running in a cluster for high availability. \xa0"),Object(i.b)("p",null,"The ",Object(i.b)("a",{parentName:"p",href:"/docs/pravega/segment-store-service"},"Segment Store")," implements the Pravega data plane.\nPravega Servers provide the API to read and write data in Streams.\xa0Data storage is comprised of two tiers:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Tier 1:"),"\xa0It provides short term, low-latency data storage,\xa0guaranteeing the durability of data written to Streams. Pravega uses\xa0",Object(i.b)("a",{parentName:"p",href:"http://bookkeeper.apache.org/"},"Apache Bookkeeper"),"\xa0to implement\nTier 1 Storage. Tier 1 Storage typically runs ",Object(i.b)("em",{parentName:"p"},"within")," the Pravega cluster.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Tier 2:")," It provides long term storage for Stream data. Pravega uses HDFS, Dell EMC's Isilon or Dell EMC's Elastic Cloud Storage (ECS) to implement Tier 2 Storage.  Tier 2 Storage is normally deployed ",Object(i.b)("em",{parentName:"p"},"outside")," the Pravega cluster."))),Object(i.b)("p",null,"Storage tiering allows Pravega to achieve a sweet spot in the latency vs throughput trade-off. This makes Pravega an ideal storage substrate for serving data to both real-time and batch (analytics) applications. Moreover, as data in Tier 1 Storage ages, it is automatically moved into Tier 2 Storage. Thus, Pravega can store vasts amounts of Stream data and applications can read it at any time, while being oblivious to its actual location."),Object(i.b)("p",null,"Pravega uses ",Object(i.b)("a",{parentName:"p",href:"https://zookeeper.apache.org/"},"Apache Zookeeper")," as the\ncoordination mechanism for the components in the Pravega cluster. \xa0"),Object(i.b)("p",null,"Pravega is a distributed storage system providing the Stream primitive first and foremost. Pravega is\ncarefully designed to take advantage of software-defined storage, so that the\namount of data stored in Pravega is limited only by the total storage capacity\nof the data center. Once an Event is written to Pravega, it is durably stored and replicated so it can survive permanent crashes of datacenter nodes."),Object(i.b)("p",null,"Pravega provides a ",Object(i.b)("strong",{parentName:"p"},"Java Client Library"),", for building client-side\napplications such as analytics applications using Flink.\xa0The Pravega Java Client\nLibrary manages the interaction between the application code and Pravega via a\ncustom TCP Wire Protocol."),Object(i.b)("h2",{id:"putting-the-concepts-together"},"Putting the Concepts Together"),Object(i.b)("p",null,"The concepts in Pravega are depicted in the following figure:"),Object(i.b)("p",null,Object(i.b)("img",{alt:"State synchroner",src:a(205).default}),"\xa0"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Pravega clients are Writers and Readers.\xa0 Writers write Events into a\nStream.\xa0Readers read Events from a Stream. Readers are grouped into\nReader Groups to read from a Stream in parallel.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"The Controller is a server-side component that manages the control plane of\nPravega.\xa0 Streams are created, updated and listed using the Controller API.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"The Pravega Server is a server-side component that implements reads, writes\nand other data plane operations.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Streams are the fundamental storage primitive in Pravega. \xa0Streams contain a\nset of data elements called Events.\xa0 Events are appended to the \u201ctail\u201d of\nthe Stream by Writers.\xa0 Readers can read Events from anywhere in the Stream.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"A Stream is\xa0partitioned into a set of Stream Segments. The number of Stream\nSegments in a Stream can change over time. \xa0Events are written into exactly\none of the Stream Segments based on Routing Key. \xa0For any Reader Group reading a Stream, each Stream Segment is assigned to one Reader in that\nReader Group.\xa0")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Each Stream Segment is stored in a combination of Tier 1 and Tier 2 Storage.\xa0\nThe tail of the Stream Segment is stored in Tier 1 providing low latency reads and\nwrites. The rest of the Stream Segment is stored in Tier 2, providing high\nthroughput read access with horizontal scalability and low cost.\xa0"))),Object(i.b)("h2",{id:"a-note-on-tiered-storage"},"A Note on Tiered Storage"),Object(i.b)("p",null,"To deliver an efficient implementation of Streams, Pravega is based on a tiered\nstorage model.\xa0 Events are persisted in low latency/high IOPS storage\xa0(Tier 1\nStorage, write-ahead log) and higher throughput Tier 2 storage (e.g., file system, object store). Writers and Readers are oblivious to the tiered storage model from an API perspective.\xa0"),Object(i.b)("p",null,"In Pravega, Tier 1 is based on an append-only ",Object(i.b)("strong",{parentName:"p"},"Log")," data structure.\xa0 As Leigh Stewart\n",Object(i.b)("a",{parentName:"p",href:"https://blog.twitter.com/2015/building-distributedlog-twitter-s-high-performance-replicated-log-service"},"observed"),",\nthere are really three data access mechanisms in a Log:"),Object(i.b)("p",null,Object(i.b)("img",{alt:"State synchroner",src:a(206).default}),"\xa0"),Object(i.b)("p",null,"All of the write activity, and much of the read activity happens at the tail of\nthe log.\xa0 Writes are appended to the log and many clients try to read data immediately as it is written to the log.\xa0These two data access mechanisms are dominated by the need for low latency \u2013 low latency writes by Writers and near real-time access to the published data by Readers."),Object(i.b)("p",null,"Please note that not all Readers read from the tail of the log. Some Readers read\nby starting at some arbitrary position in the log.\xa0 These reads are known as\n",Object(i.b)("strong",{parentName:"p"},"catch-up reads"),".\xa0 Access to historical data traditionally was done by batch\nanalytics jobs, often using HDFS and Map/Reduce.\xa0 However with new streaming\napplications, we can access historical data as well as current data by just\naccessing the log. \xa0One approach would be to store all the historical data in\nSSDs similar to tail data operations, but that leads to an expensive task and force\ncustomers to economize by deleting historical data."),Object(i.b)("p",null,"Pravega offers a mechanism that allows customers to use cost-effective, highly-scalable, high-throughput\nstorage for the historical part of the log, that way they won\u2019t have to decide on\nwhen to delete historical data.\xa0 Basically, if storage is cheap enough, why not\nkeep all of the history?"),Object(i.b)("p",null,"Tier 1 Storage aids in faster writes to the Streams by assuring durability and makes reading from the tail of a Stream much quicker.\xa0Tier 1 Storage is based on the open source Apache BookKeeper Project. Though not essential, we presume that the Tier 1 Storage will be typically implemented on faster SSDs or\neven non-volatile RAM."),Object(i.b)("p",null,"Tier 2 Storage provides a highly-scalable, high-throughput cost-effective\nstorage. We expect this Tier 2 to be typically deployed on spinning disks. Pravega\nasynchronously migrates Events from Tier 1 to Tier 2 to reflect the different\naccess patterns to Stream data. Tier 2 Storage is based on an HDFS model.\xa0"),Object(i.b)("h3",{id:"stream-retention-policies"},"Stream Retention Policies"),Object(i.b)("p",null,"Pravega allows users to store data in Tier 2 as long as there is storage capacity available. But sometimes, users may not be interested to keep all the historical data related to a Stream. Instead, there are use-cases in which it may be useful to retain just a fraction of a Stream's data. For this reason, Streams can be configured with ",Object(i.b)("strong",{parentName:"p"},"Retention Policies"),".  "),Object(i.b)("p",null,"Pravega supports two types of Retention Policies:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Time-based Retention"),": It allows the developer to control for how long the data is kept in a Stream before it is deleted. The developer can specify the time limit (milliseconds) in the Stream policy, which is ideal for situations like regulatory compliance that mandate certain retention periods.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Size-based Retention"),": Retains the newest subset of a Stream's data that does not exceed the specified size in bytes."))))}p.isMDXComponent=!0}}]);