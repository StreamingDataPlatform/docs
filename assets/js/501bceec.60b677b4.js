(window.webpackJsonp=window.webpackJsonp||[]).push([[25,53],{168:function(e,t,n){"use strict";n.d(t,"a",(function(){return u})),n.d(t,"b",(function(){return b}));var r=n(0),a=n.n(r);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function p(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?p(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):p(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var c=a.a.createContext({}),l=function(e){var t=a.a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},u=function(e){var t=l(e.components);return a.a.createElement(c.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.a.createElement(a.a.Fragment,{},t)}},m=a.a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,p=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),u=l(n),m=r,b=u["".concat(p,".").concat(m)]||u[m]||d[m]||o;return n?a.a.createElement(b,s(s({ref:t},c),{},{components:n})):a.a.createElement(b,s({ref:t},c))}));function b(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,p=new Array(o);p[0]=m;var s={};for(var i in t)hasOwnProperty.call(t,i)&&(s[i]=t[i]);s.originalType=e,s.mdxType="string"==typeof e?e:r,p[1]=s;for(var c=2;c<o;c++)p[c]=n[c];return a.a.createElement.apply(null,p)}return a.a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},57:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return p})),n.d(t,"metadata",(function(){return s})),n.d(t,"toc",(function(){return i})),n.d(t,"default",(function(){return l}));var r=n(3),a=n(7),o=(n(0),n(168)),p={},s={unversionedId:"snippets/spark-connectors/prepare-development-environment-prefix",id:"snippets/spark-connectors/prepare-development-environment-prefix",isDocsHomePage:!1,title:"prepare-development-environment-prefix",description:"SDP users can optionally skip this entire Prepare Development Environment section. However, it is often useful to develop applications locally in a sandbox environment before deploying to a production system such as SDP. For this reason, we recommend that this section is not skipped.",source:"@site/docs/snippets/spark-connectors/prepare-development-environment-prefix.md",slug:"/snippets/spark-connectors/prepare-development-environment-prefix",permalink:"/docs/docs/snippets/spark-connectors/prepare-development-environment-prefix",editUrl:null,version:"current"},i=[],c={toc:i};function l(e){var t=e.components,n=Object(a.a)(e,["components"]);return Object(o.b)("wrapper",Object(r.a)({},c,n,{components:t,mdxType:"MDXLayout"}),Object(o.b)("div",{className:"admonition admonition-tip alert alert--success"},Object(o.b)("div",{parentName:"div",className:"admonition-heading"},Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",{parentName:"h5",className:"admonition-icon"},Object(o.b)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},Object(o.b)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"Streaming Data Platform")),Object(o.b)("div",{parentName:"div",className:"admonition-content"},Object(o.b)("p",{parentName:"div"},"SDP users can optionally skip this entire ",Object(o.b)("em",{parentName:"p"},"Prepare Development Environment")," section. However, it is often useful to develop applications locally in a sandbox environment before deploying to a production system such as SDP. For this reason, we recommend that this section is not skipped."))))}l.isMDXComponent=!0},96:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return s})),n.d(t,"metadata",(function(){return i})),n.d(t,"toc",(function(){return c})),n.d(t,"default",(function(){return u}));var r=n(3),a=n(7),o=(n(0),n(168)),p=n(57),s={title:"Prepare Development Environment"},i={unversionedId:"spark-connectors/prepare-development-environment",id:"spark-connectors/prepare-development-environment",isDocsHomePage:!1,title:"Prepare Development Environment",description:"\x3c!--",source:"@site/docs/spark-connectors/prepare-development-environment.md",slug:"/spark-connectors/prepare-development-environment",permalink:"/docs/docs/spark-connectors/prepare-development-environment",editUrl:"https://github.com/pravega/spark-connectors/edit/docusaurus/documentation/src/docs/prepare-development-environment.md",version:"current",sidebar:"mainSidebar",previous:{title:"Getting Started with Spark",permalink:"/docs/docs/spark-connectors/getting-started"},next:{title:"Tutorial 1 - Writing to Pravega",permalink:"/docs/docs/spark-connectors/tutorial-1-writing-to-pravega"}},c=[{value:"Prerequisites",id:"prerequisites",children:[]},{value:"Run Pravega",id:"run-pravega",children:[]},{value:"Install Apache Spark",id:"install-apache-spark",children:[]},{value:"Clone Pravega Samples Repository",id:"clone-pravega-samples-repository",children:[]}],l={toc:c};function u(e){var t=e.components,n=Object(a.a)(e,["components"]);return Object(o.b)("wrapper",Object(r.a)({},l,n,{components:t,mdxType:"MDXLayout"}),Object(o.b)(p.default,{mdxType:"PrepareDevelopmentEnvironmentPrefix"}),Object(o.b)("h2",{id:"prerequisites"},"Prerequisites"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"Operating System"),": Spark runs on both Windows and UNIX-like systems (e.g. Linux, Mac OS), and it should run on any platform that runs a supported version of Java. The steps below show the specific steps for Ubuntu 20.04 LTS. Similar steps can be executed on other operating systems.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"Java 11"),": Java 11 JDK is required. If you are using Ubuntu, you may use these steps to install it."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-shell"},"sudo apt-get install openjdk-11-jdk\n")),Object(o.b)("p",{parentName:"li"},"  You may have multiple versions of Java installed. Ensure that Java 11 is the default with the command below."),Object(o.b)("pre",{parentName:"li"},Object(o.b)("code",{parentName:"pre",className:"language-shell"},"sudo update-alternatives --config java\n")))),Object(o.b)("h2",{id:"run-pravega"},"Run Pravega"),Object(o.b)("p",null,"This will run a development instance of Pravega locally. The transaction parameters allow transactions to remain open for up to 30 days without lease renewals."),Object(o.b)("pre",null,Object(o.b)("code",{parentName:"pre",className:"language-shell"},"cd\ngit clone https://github.com/pravega/pravega\ncd pravega\ngit checkout r0.9\n./gradlew startStandalone \\\n    -Dcontroller.transaction.lease.count.max=2592000000 \\\n    -Dcontroller.transaction.execution.timeBound.days=30\n")),Object(o.b)("h2",{id:"install-apache-spark"},"Install Apache Spark"),Object(o.b)("p",null,"This will install a development instance of Spark locally. In the steps below, we show Spark version 3.0.2 but you should use the latest 3.0.x version of Spark that is available."),Object(o.b)("p",null,"Download ",Object(o.b)("a",{parentName:"p",href:"https://www.apache.org/dyn/closer.lua/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz"},"https://www.apache.org/dyn/closer.lua/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz"),"."),Object(o.b)("pre",null,Object(o.b)("code",{parentName:"pre",className:"language-shell"},'mkdir -p ~/spark\ncd ~/spark\ntar -xzvf ~/Downloads/spark-3.0.2-bin-hadoop2.7.tgz\nln -snf spark-3.0.2-bin-hadoop2.7 current\nexport PATH="$HOME/spark/current/bin:$PATH"\n')),Object(o.b)("h2",{id:"clone-pravega-samples-repository"},"Clone Pravega Samples Repository"),Object(o.b)("p",null,"This will download the Pravega samples, which includes Spark samples written in Python and Scala. Cloning this repo is ",Object(o.b)("em",{parentName:"p"},"not")," required for Python Spark samples."),Object(o.b)("pre",null,Object(o.b)("code",{parentName:"pre",className:"language-shell"},"cd\ngit clone https://github.com/pravega/pravega-samples\ncd pravega-samples\ngit checkout spark-connector-examples --\ncd spark-connector-examples\n")))}u.isMDXComponent=!0}}]);